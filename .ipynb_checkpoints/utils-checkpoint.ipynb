{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data.dataset as dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as v_utils\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import time\n",
    "from model.utils import DataLoader,VideoDataLoader\n",
    "from model.base_model import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import *\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "def np_load_frame(filename, resize_height, resize_width):\n",
    "    \"\"\"\n",
    "    Load image path and convert it to numpy.ndarray. Notes that the color channels are BGR and the color space\n",
    "    is normalized from [0, 255] to [-1, 1].\n",
    "\n",
    "    :param filename: the full path of image\n",
    "    :param resize_height: resized height\n",
    "    :param resize_width: resized width\n",
    "    :return: numpy.ndarray\n",
    "    \"\"\"\n",
    "    image_decoded = cv2.imread(filename)\n",
    "    image_resized = cv2.resize(image_decoded, (resize_width, resize_height))\n",
    "    image_resized = image_resized.astype(dtype=np.float32)\n",
    "    image_resized = (image_resized / 127.5) - 1.0\n",
    "    return image_resized\n",
    "\n",
    "\n",
    "class VideoDataLoader(data.Dataset):\n",
    "    def __init__(self, video_folder, dataset_type, transform, resize_height, resize_width, time_step=4, segs=32, num_pred=1, batch_size=1):\n",
    "        self.dir = video_folder\n",
    "        self.dataset_type = dataset_type\n",
    "        self.transform = transform\n",
    "        self.videos = OrderedDict()\n",
    "        self.video_names = []\n",
    "        self._resize_height = resize_height\n",
    "        self._resize_width = resize_width\n",
    "        self._time_step = time_step\n",
    "        self._num_pred = num_pred\n",
    "        self.setup()\n",
    "        self.num_segs = segs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def setup(self):\n",
    "        train_folder = self.dir\n",
    "        file_name = './data/frame_'+self.dataset_type+'.pickle'\n",
    "\n",
    "        if os.path.exists(file_name):\n",
    "            file = open(file_name,'rb')\n",
    "            self.videos = pickle.load(file)\n",
    "            for name in self.videos:\n",
    "                self.video_names.append(name)\n",
    "        else:\n",
    "            videos = glob.glob(os.path.join(train_folder, '*'))\n",
    "            \n",
    "            for video in sorted(videos):\n",
    "                video_name = video.split('/')[-1]\n",
    "                self.video_names.append(video_name)\n",
    "                self.videos[video_name] = {}\n",
    "                self.videos[video_name]['path'] = video\n",
    "                self.videos[video_name]['frame'] = glob.glob(os.path.join(video, '*.jpg'))\n",
    "                self.videos[video_name]['frame'].sort()\n",
    "                self.videos[video_name]['length'] = len(self.videos[video_name]['frame'])\n",
    "            \n",
    "            \n",
    "    def get_all_samples(self):\n",
    "        frames = {}\n",
    "        videos = glob.glob(os.path.join(self.dir, '*'))\n",
    "        num = 0\n",
    "        # videos = [videos[0]]\n",
    "        for video in sorted(videos):\n",
    "            video_name = video.split('/')[-1]\n",
    "            frames[video_name] = []\n",
    "            for i in range(len(self.videos[video_name]['frame'])-self._time_step):\n",
    "                frames[video_name].append(self.videos[video_name]['frame'][i])\n",
    "                num += 1\n",
    "                           \n",
    "        return frames, num\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        video_name = self.video_names[index]\n",
    "        length = self.videos[video_name]['length']-self._time_step\n",
    "        seg_ind = random.sample(range(0, self.num_segs), self.batch_size)\n",
    "        frame_ind = random.sample(range(0, length//self.num_segs), 1)\n",
    "\n",
    "        batch = []\n",
    "        for j in range(self.batch_size):\n",
    "            frame_name = seg_ind[j]*(length//self.num_segs)+frame_ind[0]\n",
    "        \n",
    "            for i in range(self._time_step+self._num_pred):\n",
    "                image = np_load_frame(self.videos[video_name]['frame'][frame_name+i], self._resize_height, self._resize_width)\n",
    "                if self.transform is not None:\n",
    "                    batch.append(self.transform(image))\n",
    "        return np.concatenate(batch, axis=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "    \n",
    "video_folder = 'data/shanghai/training/frames'\n",
    "train_dataset = VideoDataLoader(train_folder, dataset_type, transforms.Compose([\n",
    "             transforms.ToTensor(),           \n",
    "             ]), resize_height=256, resize_width=256, time_step=4, segs=32, batch_size=1)\n",
    "\n",
    "train_size = len(train_dataset)\n",
    "train_batch = data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2, drop_last=True)\n",
    "print(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
